{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e641a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 01: prediction, Gradient computation, loss computation, parameter update  doing that manually\n",
    "# step 02: gradient computation : with autograd\n",
    "# step 03: prediction (manually), GC, autograd, LC, pythorch loss, PU, pytorch optimizer \n",
    "# step 04: all by pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c051bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\n# f = w * x \\n# f = 2 * x\\nX = np.array([1,2,3,5], dtype=np.float32)\\nY = np.array([2,2.2,2.8,3], dtype=np.float32)\\n\\n# initial w as 0\\nw = 0\\n# model prediction\\ndef forward (X):\\n    return w * X\\n\\n# loss\\n\\ndef loss(Y,y_predicted):\\n\\n    return ((y_predicted - Y)**2).mean()\\n\\n# gradient\\n\\ndef gradient(X,Y,y_predicted):\\n# MSE = 1/N * (w*x - y_predicted) **2\\n# dj/dx = 1/N * 2*x (w*x - y_predicted)\\n    return  np.dot(2*X, y_predicted - Y).mean()\\n\\n\\nprint(f\"prediction before f(5) {forward(5):.3f}\")\\n\\n# Training\\nLR = 0.01\\niter = 10'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "# f = w * x \n",
    "# f = 2 * x\n",
    "X = np.array([1,2,3,5], dtype=np.float32)\n",
    "Y = np.array([2,2.2,2.8,3], dtype=np.float32)\n",
    "\n",
    "# initial w as 0\n",
    "w = 0\n",
    "# model prediction\n",
    "def forward (X):\n",
    "    return w * X\n",
    "\n",
    "# loss\n",
    "\n",
    "def loss(Y,y_predicted):\n",
    "\n",
    "    return ((y_predicted - Y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "\n",
    "def gradient(X,Y,y_predicted):\n",
    "# MSE = 1/N * (w*x - y_predicted) **2\n",
    "# dj/dx = 1/N * 2*x (w*x - y_predicted)\n",
    "    return  np.dot(2*X, y_predicted - Y).mean()\n",
    "\n",
    "\n",
    "print(f\"prediction before f(5) {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "LR = 0.01\n",
    "iter = 10\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5151ede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for epoch in range(iter): \\n    # prediction\\n    y_pred = forward(X)\\n    #loss\\n    l = loss(Y,y_pred)\\n    # gradient\\n    dw = gradient(X,Y,y_pred)\\n\\n    # update weights\\n    w -=  LR * dw\\n    if epoch %2 == 0:\\n       print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for epoch in range(iter): \n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    #loss\n",
    "    l = loss(Y,y_pred)\n",
    "    # gradient\n",
    "    dw = gradient(X,Y,y_pred)\n",
    "\n",
    "    # update weights\n",
    "    w -=  LR * dw\n",
    "    if epoch %2 == 0:\n",
    "       print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68f1b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction after training f(5) 0.000\n"
     ]
    }
   ],
   "source": [
    "print(f\"prediction after training f(5) {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce8ef3",
   "metadata": {},
   "source": [
    "### step02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b503efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before f(5) 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# f = w * x \n",
    "# f = 2 * x\n",
    "#dataset\n",
    "X = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=torch.float32)\n",
    "Y = torch.tensor([2.0, 4.0, 6.0, 8.0], dtype=torch.float32)\n",
    "\n",
    "# initial w as 0\n",
    "w = torch.tensor(0.0, requires_grad = True)\n",
    "\n",
    "\n",
    "# model prediction\n",
    "def forward (X):\n",
    "    return w * X\n",
    "\n",
    "# loss\n",
    "\n",
    "def loss(Y,y_predicted):\n",
    "\n",
    "    return ((y_predicted - Y)**2).mean()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"prediction before f(5) {forward(5):.3f}\")\n",
    "\n",
    "# Training\n",
    "LR = 0.01\n",
    "iter = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b008fa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 2.003, loss = 0.000\n",
      "epoch 6: w = 2.001, loss = 0.000\n",
      "epoch 11: w = 2.001, loss = 0.000\n",
      "epoch 16: w = 2.000, loss = 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iter): \n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    #loss\n",
    "    l = loss(Y,y_pred)\n",
    "    # gradient = backword\n",
    "    l.backward()  #dl/dw\n",
    "\n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -=  LR * w.grad\n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch %5 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb914b",
   "metadata": {},
   "source": [
    "### Step 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6189926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before f(5) 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# f = w * x \n",
    "# f = 2 * x\n",
    "#dataset\n",
    "X = torch.tensor([1.0, 2.0, 3.0, 4.0], dtype=torch.float32)\n",
    "Y = torch.tensor([2.0, 4.0, 6.0, 8.0], dtype=torch.float32)\n",
    "\n",
    "# initial w as 0\n",
    "w = torch.tensor(0.0, requires_grad = True)\n",
    "\n",
    "\n",
    "# model prediction\n",
    "def forward (X):\n",
    "    return w * X\n",
    "\n",
    "\n",
    "print(f\"prediction before f(5) {forward(5):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: w = 0.300, loss = 30.000\n",
      "epoch 3: w = 0.772, loss = 15.660\n",
      "epoch 5: w = 1.113, loss = 8.175\n",
      "epoch 7: w = 1.359, loss = 4.267\n",
      "epoch 9: w = 1.537, loss = 2.228\n",
      "epoch 11: w = 1.665, loss = 1.163\n",
      "epoch 13: w = 1.758, loss = 0.607\n",
      "epoch 15: w = 1.825, loss = 0.317\n",
      "epoch 17: w = 1.874, loss = 0.165\n",
      "epoch 19: w = 1.909, loss = 0.086\n",
      "epoch 21: w = 1.934, loss = 0.045\n",
      "epoch 23: w = 1.952, loss = 0.024\n",
      "epoch 25: w = 1.966, loss = 0.012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training\n",
    "LR = 0.01\n",
    "iters = 25\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], LR)\n",
    "\n",
    "\n",
    "for epoch in range(iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(Y,y_pred)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 5 ==0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
